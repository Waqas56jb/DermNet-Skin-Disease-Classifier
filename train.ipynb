{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84ddd9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\burhan bajwa\\dermnet-skin-disease-classifier\\venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "857e5deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧹 Cleaning: sdc\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class: Acne and Rosacea Photos: 100%|██████████| 1400/1400 [01:09<00:00, 20.15it/s]\n",
      "Class: Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions: 100%|██████████| 1400/1400 [01:14<00:00, 18.87it/s]\n",
      "Class: Atopic Dermatitis Photos: 100%|██████████| 1400/1400 [01:04<00:00, 21.71it/s]\n",
      "Class: Bullous Disease Photos: 100%|██████████| 1400/1400 [01:03<00:00, 21.96it/s]\n",
      "Class: Cellulitis Impetigo and other Bacterial Infections: 100%|██████████| 1400/1400 [01:00<00:00, 23.10it/s]\n",
      "Class: Eczema Photos: 100%|██████████| 1400/1400 [01:16<00:00, 18.31it/s]\n",
      "Class: Exanthems and Drug Eruptions: 100%|██████████| 1400/1400 [01:01<00:00, 22.70it/s]\n",
      "Class: Hair Loss Photos Alopecia and other Hair Diseases: 100%|██████████| 1400/1400 [01:02<00:00, 22.29it/s]\n",
      "Class: Herpes HPV and other STDs Photos: 100%|██████████| 1400/1400 [01:03<00:00, 22.12it/s]\n",
      "Class: Light Diseases and Disorders of Pigmentation: 100%|██████████| 1400/1400 [01:04<00:00, 21.67it/s]\n",
      "Class: Lupus and other Connective Tissue diseases: 100%|██████████| 1400/1400 [01:02<00:00, 22.36it/s]\n",
      "Class: Melanoma Skin Cancer Nevi and Moles: 100%|██████████| 1400/1400 [01:05<00:00, 21.44it/s]\n",
      "Class: Nail Fungus and other Nail Disease: 100%|██████████| 1400/1400 [01:10<00:00, 19.75it/s]\n",
      "Class: Poison Ivy Photos and other Contact Dermatitis: 100%|██████████| 1400/1400 [01:02<00:00, 22.53it/s]\n",
      "Class: Psoriasis pictures Lichen Planus and related diseases: 100%|██████████| 1400/1400 [01:55<00:00, 12.12it/s]\n",
      "Class: Scabies Lyme Disease and other Infestations and Bites: 100%|██████████| 1400/1400 [01:01<00:00, 22.59it/s]\n",
      "Class: Seborrheic Keratoses and other Benign Tumors: 100%|██████████| 1400/1400 [01:18<00:00, 17.82it/s]\n",
      "Class: Systemic Disease: 100%|██████████| 1400/1400 [01:08<00:00, 20.44it/s]\n",
      "Class: Tinea Ringworm Candidiasis and other Fungal Infections: 100%|██████████| 1400/1400 [01:24<00:00, 16.65it/s]\n",
      "Class: Urticaria Hives: 100%|██████████| 1400/1400 [01:11<00:00, 19.46it/s]\n",
      "Class: Vascular Tumors: 100%|██████████| 1400/1400 [01:06<00:00, 21.19it/s]\n",
      "Class: Vasculitis Photos: 100%|██████████| 1400/1400 [01:02<00:00, 22.46it/s]\n",
      "Class: Warts Molluscum and other Viral Infections: 100%|██████████| 1400/1400 [01:17<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Total removed: 32200\n",
      "\n",
      "🧹 Cleaning: sdc\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class: Acne and Rosacea Photos: 100%|██████████| 312/312 [00:18<00:00, 17.13it/s]\n",
      "Class: Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions: 100%|██████████| 288/288 [00:17<00:00, 16.30it/s]\n",
      "Class: Atopic Dermatitis Photos: 100%|██████████| 123/123 [00:09<00:00, 13.10it/s]\n",
      "Class: Bullous Disease Photos: 100%|██████████| 113/113 [00:06<00:00, 16.90it/s]\n",
      "Class: Cellulitis Impetigo and other Bacterial Infections: 100%|██████████| 73/73 [00:04<00:00, 17.21it/s]\n",
      "Class: Eczema Photos: 100%|██████████| 309/309 [00:18<00:00, 16.58it/s]\n",
      "Class: Exanthems and Drug Eruptions: 100%|██████████| 101/101 [00:06<00:00, 16.68it/s]\n",
      "Class: Hair Loss Photos Alopecia and other Hair Diseases: 100%|██████████| 60/60 [00:03<00:00, 16.51it/s]\n",
      "Class: Herpes HPV and other STDs Photos: 100%|██████████| 102/102 [00:07<00:00, 13.36it/s]\n",
      "Class: Light Diseases and Disorders of Pigmentation: 100%|██████████| 143/143 [00:10<00:00, 14.02it/s]\n",
      "Class: Lupus and other Connective Tissue diseases: 100%|██████████| 105/105 [00:07<00:00, 13.24it/s]\n",
      "Class: Melanoma Skin Cancer Nevi and Moles: 100%|██████████| 116/116 [00:07<00:00, 16.09it/s]\n",
      "Class: Nail Fungus and other Nail Disease: 100%|██████████| 261/261 [00:15<00:00, 16.90it/s]\n",
      "Class: Poison Ivy Photos and other Contact Dermatitis: 100%|██████████| 65/65 [00:04<00:00, 15.77it/s]\n",
      "Class: Psoriasis pictures Lichen Planus and related diseases: 100%|██████████| 352/352 [00:20<00:00, 17.06it/s]\n",
      "Class: Scabies Lyme Disease and other Infestations and Bites: 100%|██████████| 108/108 [00:06<00:00, 17.81it/s]\n",
      "Class: Seborrheic Keratoses and other Benign Tumors: 100%|██████████| 343/343 [00:20<00:00, 16.84it/s]\n",
      "Class: Systemic Disease: 100%|██████████| 152/152 [00:10<00:00, 14.18it/s]\n",
      "Class: Tinea Ringworm Candidiasis and other Fungal Infections: 100%|██████████| 325/325 [00:27<00:00, 11.66it/s]\n",
      "Class: Urticaria Hives: 100%|██████████| 53/53 [00:04<00:00, 10.77it/s]\n",
      "Class: Vascular Tumors: 100%|██████████| 121/121 [00:19<00:00,  6.06it/s]\n",
      "Class: Vasculitis Photos: 100%|██████████| 105/105 [00:09<00:00, 10.85it/s]\n",
      "Class: Warts Molluscum and other Viral Infections: 100%|██████████| 272/272 [00:16<00:00, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Total removed: 4002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.stats import entropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------ Config ------------\n",
    "DATASET_DIR = \"sdc\"\n",
    "THRESH_BLUR = 100             # Laplacian variance threshold (blurriness)\n",
    "THRESH_ENTROPY = 2.0          # Entropy threshold (uninformative)\n",
    "THRESH_VEC_NORM = 10.0        # Feature vector norm (low context)\n",
    "# --------------------------------\n",
    "\n",
    "# Load EfficientNet for embedding extraction\n",
    "base_model = EfficientNetB0(include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def is_blurry(img_path, threshold=THRESH_BLUR):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return True\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() < threshold\n",
    "\n",
    "def is_low_entropy(img_path, threshold=THRESH_ENTROPY):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        hist = np.array(img.histogram())\n",
    "        hist = hist / hist.sum()\n",
    "        return entropy(hist) < threshold\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def is_low_feature_vector(img_path, threshold=THRESH_VEC_NORM):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))\n",
    "        vec = model.predict(x, verbose=0)[0]\n",
    "        return np.linalg.norm(vec) < threshold\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def clean_folder(folder_path):\n",
    "    print(f\"\\n🧹 Cleaning: {folder_path}\")\n",
    "    total_removed = 0\n",
    "    for cls in os.listdir(folder_path):\n",
    "        cls_path = os.path.join(folder_path, cls)\n",
    "        if not os.path.isdir(cls_path): continue\n",
    "\n",
    "        for fname in tqdm(os.listdir(cls_path), desc=f\"Class: {cls}\"):\n",
    "            img_path = os.path.join(cls_path, fname)\n",
    "\n",
    "            if (\n",
    "                is_blurry(img_path) or\n",
    "                is_low_entropy(img_path) or\n",
    "                is_low_feature_vector(img_path)\n",
    "            ):\n",
    "                os.remove(img_path)\n",
    "                total_removed += 1\n",
    "\n",
    "    print(f\"✅ Done. Total removed: {total_removed}\")\n",
    "\n",
    "# Run cleaning on train and test folders\n",
    "clean_folder(os.path.join(DATASET_DIR, \"train\"))\n",
    "clean_folder(os.path.join(DATASET_DIR, \"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "692aa17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train...\n",
      "Processing val...\n",
      "✅ Done. Resized ALL images per class to 1920x1080 and saved in 'temp' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Source and target directories\n",
    "SOURCE_DIR = 'dataset'\n",
    "TARGET_DIR = 'dataset'\n",
    "IMG_SIZE = (1920, 1080)\n",
    "\n",
    "# Ensure target directories exist\n",
    "for subset in ['train', 'val']:\n",
    "    for class_name in os.listdir(os.path.join(SOURCE_DIR, subset)):\n",
    "        os.makedirs(os.path.join(TARGET_DIR, subset, class_name), exist_ok=True)\n",
    "\n",
    "# Function to copy & resize images\n",
    "def process_images(subset):\n",
    "    print(f\"Processing {subset}...\")\n",
    "    src_path = os.path.join(SOURCE_DIR, subset)\n",
    "    tgt_path = os.path.join(TARGET_DIR, subset)\n",
    "\n",
    "    for class_name in os.listdir(src_path):\n",
    "        class_src = os.path.join(src_path, class_name)\n",
    "        class_tgt = os.path.join(tgt_path, class_name)\n",
    "\n",
    "        images = os.listdir(class_src)\n",
    "        for img_name in images:\n",
    "            try:\n",
    "                img_src_path = os.path.join(class_src, img_name)\n",
    "                img_tgt_path = os.path.join(class_tgt, img_name)\n",
    "\n",
    "                img = Image.open(img_src_path).convert('RGB')\n",
    "                img = img.resize(IMG_SIZE)\n",
    "                img.save(img_tgt_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {img_name}: {e}\")\n",
    "\n",
    "# Run for both subsets\n",
    "process_images('train')\n",
    "process_images('val')\n",
    "\n",
    "print(\"✅ Done. Resized ALL images per class to 1920x1080 and saved in 'temp' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09283ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Augmenting each image in: train\n",
      "📁 Class: Actinic keratosis - 80 original images\n",
      "📁 Class: Atopic Dermatitis - 81 original images\n",
      "📁 Class: Benign keratosis - 80 original images\n",
      "📁 Class: Dermatofibroma - 80 original images\n",
      "📁 Class: Melanocytic nevus - 80 original images\n",
      "📁 Class: Melanoma - 80 original images\n",
      "📁 Class: Squamous cell carcinoma - 80 original images\n",
      "📁 Class: Tinea Ringworm Candidiasis - 56 original images\n",
      "❌ Failed on aug_0_natural-treatment-Daad-khaj-khujli-ringworm-home-treatment-home-remedies-fungal-infection-treatment-symptom-pictures-diagnosis-hindi-gimtrend.blogspot.com.jpeg: [Errno 2] No such file or directory: 'dataset\\\\train\\\\Tinea Ringworm Candidiasis\\\\aug_27_aug_0_natural-treatment-Daad-khaj-khujli-ringworm-home-treatment-home-remedies-fungal-infection-treatment-symptom-pictures-diagnosis-hindi-gimtrend.blogspot.com.jpeg'\n",
      "📁 Class: Vascular lesion - 80 original images\n",
      "\n",
      "🔄 Augmenting each image in: val\n",
      "📁 Class: Actinic keratosis - 20 original images\n",
      "📁 Class: Atopic Dermatitis - 21 original images\n",
      "📁 Class: Benign keratosis - 20 original images\n",
      "📁 Class: Dermatofibroma - 20 original images\n",
      "📁 Class: Melanocytic nevus - 20 original images\n",
      "📁 Class: Melanoma - 20 original images\n",
      "📁 Class: Squamous cell carcinoma - 20 original images\n",
      "📁 Class: Tinea Ringworm Candidiasis - 20 original images\n",
      "📁 Class: Vascular lesion - 20 original images\n",
      "\n",
      "✅ Done. 1 augmented image per original (Full HD) saved in 'temp/train' and 'temp/test'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "\n",
    "# Working Directory\n",
    "DATASET_DIR = 'dataset'\n",
    "IMG_SIZE = (1920, 1080)\n",
    "\n",
    "# Create augmentor once\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_each_image_once(subset):\n",
    "    print(f\"\\n🔄 Augmenting each image in: {subset}\")\n",
    "    subset_path = os.path.join(DATASET_DIR, subset)\n",
    "\n",
    "    for class_name in os.listdir(subset_path):\n",
    "        class_dir = os.path.join(subset_path, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        images = [img for img in os.listdir(class_dir) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"📁 Class: {class_name} - {len(images)} original images\")\n",
    "\n",
    "        for idx, img_name in enumerate(images):\n",
    "            try:\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = load_img(img_path).resize(IMG_SIZE)\n",
    "                x = img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "\n",
    "                # Generate 1 augmented version\n",
    "                for batch in augmentor.flow(x, batch_size=1):\n",
    "                    aug_img = array_to_img(batch[0]).resize(IMG_SIZE)\n",
    "                    aug_name = f\"aug_{idx}_{img_name}\"\n",
    "                    aug_img.save(os.path.join(class_dir, aug_name))\n",
    "                    break  # Only 1 augmented image per original\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed on {img_name}: {e}\")\n",
    "\n",
    "# Apply to both subsets\n",
    "augment_each_image_once('train')\n",
    "augment_each_image_once('val')\n",
    "\n",
    "print(\"\\n✅ Done. 1 augmented image per original (Full HD) saved in 'temp/train' and 'temp/test'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85bb258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 460 images from sdc\\train | Skipped 0 non-image files.\n",
      "Sample labels (first 5): [0, 0, 0, 0, 0] - Types: [<class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>]\n",
      "Loaded 460 images from sdc\\test | Skipped 0 non-image files.\n",
      "Sample labels (first 5): [0, 0, 0, 0, 0] - Types: [<class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>]\n",
      "train_labels_flat content (first 5): [15 16 13 17 16]\n",
      "train_labels_flat types (first 5): [<class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>]\n",
      "Validation set size: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\S/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch 1/20, Loss: 3.2414, Val Accuracy: 0.0217\n",
      "Epoch 2/20, Loss: 3.1895, Val Accuracy: 0.0435\n",
      "Epoch 3/20, Loss: 3.1337, Val Accuracy: 0.0435\n",
      "Epoch 4/20, Loss: 3.1092, Val Accuracy: 0.1957\n",
      "Epoch 5/20, Loss: 3.0832, Val Accuracy: 0.2174\n",
      "Epoch 6/20, Loss: 3.0529, Val Accuracy: 0.3043\n",
      "Epoch 7/20, Loss: 2.9951, Val Accuracy: 0.3913\n",
      "Epoch 8/20, Loss: 2.9123, Val Accuracy: 0.5870\n",
      "Epoch 9/20, Loss: 2.8020, Val Accuracy: 0.4130\n",
      "Epoch 10/20, Loss: 2.6800, Val Accuracy: 0.5217\n",
      "Epoch 11/20, Loss: 2.4345, Val Accuracy: 0.6957\n",
      "Epoch 12/20, Loss: 2.1872, Val Accuracy: 0.8261\n",
      "Epoch 13/20, Loss: 1.9574, Val Accuracy: 0.8913\n",
      "Epoch 14/20, Loss: 1.7194, Val Accuracy: 0.8261\n",
      "Epoch 15/20, Loss: 1.4885, Val Accuracy: 0.8478\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 291\u001b[0m\n\u001b[0;32m    288\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "Cell \u001b[1;32mIn[3], line 255\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m    253\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images, symptoms\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m    254\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m--> 255\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    257\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from random import randint, sample\n",
    "\n",
    "# --- Paths ---\n",
    "BASE_DIR = 'sdc'  # Your dataset path\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "OUTPUT_DIR = 'output'  # For saving models\n",
    "\n",
    "# --- Parameters ---\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "NUM_CLASSES = 23\n",
    "IMAGES_PER_CLASS = 20  # Select exactly 20 images per class\n",
    "VALIDATION_SPLIT = 0.1  # Split train into 90% train, 10% validation\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device(\"cpu\")  # CPU-only setup\n",
    "\n",
    "# --- Disease and Symptom Definitions ---\n",
    "disease_to_index = {\n",
    "    \"Acne and Rosacea Photos\": 0,\n",
    "    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\": 1,\n",
    "    \"Atopic Dermatitis Photos\": 2,\n",
    "    \"Bullous Disease Photos\": 3,\n",
    "    \"Cellulitis Impetigo and other Bacterial Infections\": 4,\n",
    "    \"Eczema Photos\": 5,\n",
    "    \"Exanthems and Drug Eruptions\": 6,\n",
    "    \"Hair Loss Photos Alopecia and other Hair Diseases\": 7,\n",
    "    \"Herpes HPV and other STDs Photos\": 8,\n",
    "    \"Light Diseases and Disorders of Pigmentation\": 9,\n",
    "    \"Lupus and other Connective Tissue diseases\": 10,\n",
    "    \"Melanoma Skin Cancer Nevi and Moles\": 11,\n",
    "    \"Nail Fungus and other Nail Disease\": 12,\n",
    "    \"Poison Ivy Photos and other Contact Dermatitis\": 13,\n",
    "    \"Psoriasis pictures Lichen Planus and related diseases\": 14,\n",
    "    \"Scabies Lyme Disease and other Infestations and Bites\": 15,\n",
    "    \"Seborrheic Keratoses and other Benign Tumors\": 16,\n",
    "    \"Systemic Disease\": 17,\n",
    "    \"Tinea Ringworm Candidiasis and other Fungal Infections\": 18,\n",
    "    \"Urticaria Hives\": 19,\n",
    "    \"Vascular Tumors\": 20,\n",
    "    \"Vasculitis Photos\": 21,\n",
    "    \"Warts Molluscum and other Viral Infections\": 22\n",
    "}\n",
    "\n",
    "disease_symptoms = {\n",
    "    \"Acne and Rosacea Photos\": [\"pimples\", \"redness\", \"pustules\", \"facial_flushing\", \"papules\"],\n",
    "    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\": [\"scaly_patches\", \"pearly_nodule\", \"ulceration\", \"bleeding\", \"telangiectasia\"],\n",
    "    \"Atopic Dermatitis Photos\": [\"itching\", \"redness\", \"dry_skin\", \"crusting\", \"swelling\"],\n",
    "    \"Bullous Disease Photos\": [\"blisters\", \"erosions\", \"itching\", \"painful_lesions\", \"fluid_filled\"],\n",
    "    \"Cellulitis Impetigo and other Bacterial Infections\": [\"redness\", \"swelling\", \"warmth\", \"pain\", \"pustules\"],\n",
    "    \"Eczema Photos\": [\"redness\", \"itching\", \"dryness\", \"scaling\", \"swelling\"],\n",
    "    \"Exanthems and Drug Eruptions\": [\"rash\", \"red_spots\", \"itching\", \"widespread_lesions\", \"fever\"],\n",
    "    \"Hair Loss Photos Alopecia and other Hair Diseases\": [\"hair_thinning\", \"bald_patches\", \"scalp_itching\", \"scaling\", \"redness\"],\n",
    "    \"Herpes HPV and other STDs Photos\": [\"blisters\", \"ulcers\", \"pain\", \"itching\", \"crusting\"],\n",
    "    \"Light Diseases and Disorders of Pigmentation\": [\"hypopigmentation\", \"hyperpigmentation\", \"flat_spots\", \"itching\", \"sun_sensitivity\"],\n",
    "    \"Lupus and other Connective Tissue diseases\": [\"butterfly_rash\", \"joint_pain\", \"photosensitivity\", \"red_patches\", \"scaling\"],\n",
    "    \"Melanoma Skin Cancer Nevi and Moles\": [\"asymmetry\", \"irregular_border\", \"color_variation\", \"diameter\", \"evolving\"],\n",
    "    \"Nail Fungus and other Nail Disease\": [\"nail_thickening\", \"discoloration\", \"brittle_nails\", \"deformity\", \"pain\"],\n",
    "    \"Poison Ivy Photos and other Contact Dermatitis\": [\"redness\", \"itching\", \"blisters\", \"swelling\", \"linear_rash\"],\n",
    "    \"Psoriasis pictures Lichen Planus and related diseases\": [\"red_patches\", \"silvery_scales\", \"itching\", \"plaques\", \"joint_pain\"],\n",
    "    \"Scabies Lyme Disease and other Infestations and Bites\": [\"itching\", \"red_bumps\", \"burrows\", \"rash\", \"bullseye_rash\"],\n",
    "    \"Seborrheic Keratoses and other Benign Tumors\": [\"waxy_growth\", \"brown_black_color\", \"stuck_on_appearance\", \"itching\", \"scaling\"],\n",
    "    \"Systemic Disease\": [\"rash\", \"fatigue\", \"fever\", \"joint_pain\", \"organ_involvement\"],\n",
    "    \"Tinea Ringworm Candidiasis and other Fungal Infections\": [\"ring_shaped_rash\", \"itching\", \"scaling\", \"redness\", \"crusting\"],\n",
    "    \"Urticaria Hives\": [\"wheals\", \"itching\", \"redness\", \"swelling\", \"transient_lesions\"],\n",
    "    \"Vascular Tumors\": [\"red_nodules\", \"growth\", \"bleeding\", \"painless\", \"vascular_markings\"],\n",
    "    \"Vasculitis Photos\": [\"purpura\", \"red_spots\", \"painful_nodules\", \"ulcers\", \"joint_pain\"],\n",
    "    \"Warts Molluscum and other Viral Infections\": [\"small_bumps\", \"painless_nodules\", \"itching\", \"rough_surface\", \"clustered_lesions\"]\n",
    "}\n",
    "\n",
    "all_possible_symptoms = list(set(sum(disease_symptoms.values(), [])))\n",
    "symptom_to_index = {sym: idx for idx, sym in enumerate(all_possible_symptoms)}\n",
    "num_symptoms = len(all_possible_symptoms)\n",
    "\n",
    "# --- Load Image Paths with Limit of 20 Images per Class ---\n",
    "def load_images_from_split(split_dir, split_name):\n",
    "    images, labels = [], []\n",
    "    non_image_files = 0\n",
    "    for disease in os.listdir(split_dir):\n",
    "        disease_dir = os.path.join(split_dir, disease)\n",
    "        if os.path.isdir(disease_dir) and disease in disease_to_index:\n",
    "            class_images = [\n",
    "                os.path.join(disease_dir, img_file)\n",
    "                for img_file in os.listdir(disease_dir)\n",
    "                if img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"))\n",
    "            ]\n",
    "            if len(class_images) < IMAGES_PER_CLASS:\n",
    "                print(f\"Warning: {disease} in {split_name} has only {len(class_images)} images, using all available.\")\n",
    "            selected_images = random.sample(class_images, min(len(class_images), IMAGES_PER_CLASS))\n",
    "            images.extend(selected_images)\n",
    "            labels.extend([disease_to_index[disease]] * len(selected_images))\n",
    "            non_image_files += len([f for f in os.listdir(disease_dir) if not f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"))])\n",
    "    print(f\"Loaded {len(images)} images from {split_dir} | Skipped {non_image_files} non-image files.\")\n",
    "    print(f\"Sample labels (first 5): {labels[:5]} - Types: {[type(l) for l in labels[:5]]}\")\n",
    "    return images, labels\n",
    "\n",
    "# --- Symptom Encoding ---\n",
    "def generate_symptom_array(label_index):\n",
    "    disease_name = list(disease_to_index.keys())[label_index]\n",
    "    symptoms = disease_symptoms[disease_name]\n",
    "    return sample(symptoms, randint(1, len(symptoms)))\n",
    "\n",
    "def encode_symptoms(symptom_list):\n",
    "    encoding = np.zeros(num_symptoms)\n",
    "    for sym in symptom_list:\n",
    "        encoding[symptom_to_index[sym]] = 1\n",
    "    return encoding\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, images, symptoms, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.symptoms = symptoms\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images[idx])\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, self.symptoms[idx], self.labels[idx]\n",
    "        return None, None, None\n",
    "\n",
    "# --- Data Preparation ---\n",
    "data = {}\n",
    "train_labels_flat = []\n",
    "\n",
    "# Load train and test images\n",
    "train_images, train_labels = load_images_from_split(TRAIN_DIR, \"train\")\n",
    "test_images, test_labels = load_images_from_split(TEST_DIR, \"test\")\n",
    "\n",
    "# Split train images into train and validation sets\n",
    "total_train_images = len(train_images)\n",
    "val_size = int(total_train_images * VALIDATION_SPLIT)\n",
    "train_size = total_train_images - val_size\n",
    "\n",
    "idx = list(range(total_train_images))\n",
    "random.shuffle(idx)\n",
    "train_idx = idx[:train_size]\n",
    "val_idx = idx[train_size:]\n",
    "\n",
    "# Ensure val_idx does not exceed original list length\n",
    "train_images_subset = [train_images[i] for i in train_idx]\n",
    "train_labels_subset = [train_labels[i] for i in train_idx]\n",
    "val_images_subset = [train_images[i] for i in val_idx if i < total_train_images]\n",
    "val_labels_subset = [train_labels[i] for i in val_idx if i < total_train_images]\n",
    "\n",
    "# Prepare symptoms and labels\n",
    "train_symptom_arrays = [generate_symptom_array(label) for label in train_labels_subset]\n",
    "train_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in train_symptom_arrays])\n",
    "val_symptom_arrays = [generate_symptom_array(label) for label in val_labels_subset]\n",
    "val_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in val_symptom_arrays])\n",
    "test_symptom_arrays = [generate_symptom_array(label) for label in test_labels]\n",
    "test_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in test_symptom_arrays])\n",
    "\n",
    "# Data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinDiseaseDataset(train_images_subset, train_encoded_symptoms, train_labels_subset, transform=data_transforms)\n",
    "val_dataset = SkinDiseaseDataset(val_images_subset, val_encoded_symptoms, val_labels_subset, transform=data_transforms)\n",
    "test_dataset = SkinDiseaseDataset(test_images, test_encoded_symptoms, test_labels, transform=data_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_labels_flat = np.array(train_labels_subset)\n",
    "\n",
    "# --- Debug Check ---\n",
    "print(f\"train_labels_flat content (first 5): {train_labels_flat[:5]}\")\n",
    "print(f\"train_labels_flat types (first 5): {[type(l) for l in train_labels_flat[:5]]}\")\n",
    "print(f\"Validation set size: {len(val_images_subset)}\")\n",
    "\n",
    "# --- Class Weights ---\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels_flat), y=train_labels_flat)\n",
    "class_weights = torch.FloatTensor(class_weights_array).to(device)\n",
    "\n",
    "# --- Model Builder ---\n",
    "class SkinDiseaseModel(nn.Module):\n",
    "    def __init__(self, num_symptoms):\n",
    "        super(SkinDiseaseModel, self).__init__()\n",
    "        self.base = models.resnet50(pretrained=True)\n",
    "        num_ftrs = self.base.fc.in_features\n",
    "        self.base.fc = nn.Identity()\n",
    "        self.image_fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.symptom_fc = nn.Sequential(\n",
    "            nn.Linear(num_symptoms, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.combined_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, symptoms):\n",
    "        x = self.base(image)\n",
    "        x = self.image_fc(x)\n",
    "        y = self.symptom_fc(symptoms)\n",
    "        combined = torch.cat((x, y), dim=1)\n",
    "        out = self.combined_fc(combined)\n",
    "        return out\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, symptoms, labels in train_loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images, symptoms, labels = images.to(device), symptoms.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, symptoms.float())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Val Accuracy: {val_acc:.4f}')\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pth'))\n",
    "    return model\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, symptoms, labels in loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images, symptoms, labels = images.to(device), symptoms.to(device), labels.to(device)\n",
    "            outputs = model(images, symptoms.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    model = SkinDiseaseModel(num_symptoms).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS)\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best_model.pth')))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, symptoms, labels in test_loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images, symptoms, labels = images.to(device), symptoms.to(device), labels.to(device)\n",
    "            outputs = model(images, symptoms.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=list(disease_to_index.keys())))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(disease_to_index.keys()), yticklabels=list(disease_to_index.keys()))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nAdditional Metrics:\")\n",
    "    print(f\"F1 Score: {f1_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
    "    print(f\"Precision: {precision_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
    "    print(f\"Recall: {recall_score(all_labels, all_preds, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c740a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 images from sdc\\train | Skipped 0 non-image files.\n",
      "Sample labels (first 5): [0, 0, 0, 0, 0] - Types: [<class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>]\n",
      "Loaded 437 images from sdc\\test | Skipped 0 non-image files.\n",
      "Sample labels (first 5): [0, 0, 0, 0, 0] - Types: [<class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>]\n",
      "train_labels_flat content (first 5): [ 5 12 22  9 19]\n",
      "train_labels_flat types (first 5): [<class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>]\n",
      "Validation set size: 43\n",
      "\n",
      "Training EfficientNetB0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Burhan Bajwa\\DermNet-Skin-Disease-Classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 453\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, base_model \u001b[38;5;129;01min\u001b[39;00m models_to_run:\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSkinDiseaseModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_symptoms\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    454\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[0;32m    455\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 232\u001b[0m, in \u001b[0;36mSkinDiseaseModel.__init__\u001b[1;34m(self, base_model, num_symptoms, pretrained)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mIdentity()\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Fine-tune last few layers\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m    233\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_fc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m    236\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;241m1024\u001b[39m),\n\u001b[0;32m    237\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m    243\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from random import randint, sample\n",
    "\n",
    "# --- Paths ---\n",
    "BASE_DIR = 'sdc'  # Your dataset path\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "OUTPUT_DIR = 'output'  # For saving models\n",
    "\n",
    "# --- Parameters ---\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # Increased for potential 90%+ accuracy\n",
    "NUM_CLASSES = 23\n",
    "IMAGES_PER_CLASS = 19  # Select exactly 19 images per class\n",
    "VALIDATION_SPLIT = 0.1  # 10% validation split\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Disease and Symptom Definitions ---\n",
    "disease_to_index = {\n",
    "    \"Acne and Rosacea Photos\": 0,\n",
    "    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\": 1,\n",
    "    \"Atopic Dermatitis Photos\": 2,\n",
    "    \"Bullous Disease Photos\": 3,\n",
    "    \"Cellulitis Impetigo and other Bacterial Infections\": 4,\n",
    "    \"Eczema Photos\": 5,\n",
    "    \"Exanthems and Drug Eruptions\": 6,\n",
    "    \"Hair Loss Photos Alopecia and other Hair Diseases\": 7,\n",
    "    \"Herpes HPV and other STDs Photos\": 8,\n",
    "    \"Light Diseases and Disorders of Pigmentation\": 9,\n",
    "    \"Lupus and other Connective Tissue diseases\": 10,\n",
    "    \"Melanoma Skin Cancer Nevi and Moles\": 11,\n",
    "    \"Nail Fungus and other Nail Disease\": 12,\n",
    "    \"Poison Ivy Photos and other Contact Dermatitis\": 13,\n",
    "    \"Psoriasis pictures Lichen Planus and related diseases\": 14,\n",
    "    \"Scabies Lyme Disease and other Infestations and Bites\": 15,\n",
    "    \"Seborrheic Keratoses and other Benign Tumors\": 16,\n",
    "    \"Systemic Disease\": 17,\n",
    "    \"Tinea Ringworm Candidiasis and other Fungal Infections\": 18,\n",
    "    \"Urticaria Hives\": 19,\n",
    "    \"Vascular Tumors\": 20,\n",
    "    \"Vasculitis Photos\": 21,\n",
    "    \"Warts Molluscum and other Viral Infections\": 22\n",
    "}\n",
    "\n",
    "disease_symptoms = {\n",
    "    \"Acne and Rosacea Photos\": [\"pimples\", \"redness\", \"pustules\", \"facial_flushing\", \"papules\"],\n",
    "    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\": [\"scaly_patches\", \"pearly_nodule\", \"ulceration\", \"bleeding\", \"telangiectasia\"],\n",
    "    \"Atopic Dermatitis Photos\": [\"itching\", \"redness\", \"dry_skin\", \"crusting\", \"swelling\"],\n",
    "    \"Bullous Disease Photos\": [\"blisters\", \"erosions\", \"itching\", \"painful_lesions\", \"fluid_filled\"],\n",
    "    \"Cellulitis Impetigo and other Bacterial Infections\": [\"redness\", \"swelling\", \"warmth\", \"pain\", \"pustules\"],\n",
    "    \"Eczema Photos\": [\"redness\", \"itching\", \"dryness\", \"scaling\", \"swelling\"],\n",
    "    \"Exanthems and Drug Eruptions\": [\"rash\", \"red_spots\", \"itching\", \"widespread_lesions\", \"fever\"],\n",
    "    \"Hair Loss Photos Alopecia and other Hair Diseases\": [\"hair_thinning\", \"bald_patches\", \"scalp_itching\", \"scaling\", \"redness\"],\n",
    "    \"Herpes HPV and other STDs Photos\": [\"blisters\", \"ulcers\", \"pain\", \"itching\", \"crusting\"],\n",
    "    \"Light Diseases and Disorders of Pigmentation\": [\"hypopigmentation\", \"hyperpigmentation\", \"flat_spots\", \"itching\", \"sun_sensitivity\"],\n",
    "    \"Lupus and other Connective Tissue diseases\": [\"butterfly_rash\", \"joint_pain\", \"photosensitivity\", \"red_patches\", \"scaling\"],\n",
    "    \"Melanoma Skin Cancer Nevi and Moles\": [\"asymmetry\", \"irregular_border\", \"color_variation\", \"diameter\", \"evolving\"],\n",
    "    \"Nail Fungus and other Nail Disease\": [\"nail_thickening\", \"discoloration\", \"brittle_nails\", \"deformity\", \"pain\"],\n",
    "    \"Poison Ivy Photos and other Contact Dermatitis\": [\"redness\", \"itching\", \"blisters\", \"swelling\", \"linear_rash\"],\n",
    "    \"Psoriasis pictures Lichen Planus and related diseases\": [\"red_patches\", \"silvery_scales\", \"itching\", \"plaques\", \"joint_pain\"],\n",
    "    \"Scabies Lyme Disease and other Infestations and Bites\": [\"itching\", \"red_bumps\", \"burrows\", \"rash\", \"bullseye_rash\"],\n",
    "    \"Seborrheic Keratoses and other Benign Tumors\": [\"waxy_growth\", \"brown_black_color\", \"stuck_on_appearance\", \"itching\", \"scaling\"],\n",
    "    \"Systemic Disease\": [\"rash\", \"fatigue\", \"fever\", \"joint_pain\", \"organ_involvement\"],\n",
    "    \"Tinea Ringworm Candidiasis and other Fungal Infections\": [\"ring_shaped_rash\", \"itching\", \"scaling\", \"redness\", \"crusting\"],\n",
    "    \"Urticaria Hives\": [\"wheals\", \"itching\", \"redness\", \"swelling\", \"transient_lesions\"],\n",
    "    \"Vascular Tumors\": [\"red_nodules\", \"growth\", \"bleeding\", \"painless\", \"vascular_markings\"],\n",
    "    \"Vasculitis Photos\": [\"purpura\", \"red_spots\", \"painful_nodules\", \"ulcers\", \"joint_pain\"],\n",
    "    \"Warts Molluscum and other Viral Infections\": [\"small_bumps\", \"painless_nodules\", \"itching\", \"rough_surface\", \"clustered_lesions\"]\n",
    "}\n",
    "\n",
    "all_possible_symptoms = list(set(sum(disease_symptoms.values(), [])))\n",
    "symptom_to_index = {sym: idx for idx, sym in enumerate(all_possible_symptoms)}\n",
    "num_symptoms = len(all_possible_symptoms)\n",
    "\n",
    "# --- Load Image Paths with Limit of 19 Images per Class ---\n",
    "def load_images_from_split(split_dir, split_name):\n",
    "    images, labels = [], []\n",
    "    non_image_files = 0\n",
    "    for disease in os.listdir(split_dir):\n",
    "        disease_dir = os.path.join(split_dir, disease)\n",
    "        if os.path.isdir(disease_dir) and disease in disease_to_index:\n",
    "            class_images = [\n",
    "                os.path.join(disease_dir, img_file)\n",
    "                for img_file in os.listdir(disease_dir)\n",
    "                if img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"))\n",
    "            ]\n",
    "            if len(class_images) < IMAGES_PER_CLASS:\n",
    "                print(f\"Warning: {disease} in {split_name} has only {len(class_images)} images, using all available.\")\n",
    "            selected_images = random.sample(class_images, min(len(class_images), IMAGES_PER_CLASS))\n",
    "            images.extend(selected_images)\n",
    "            labels.extend([disease_to_index[disease]] * len(selected_images))\n",
    "            non_image_files += len([f for f in os.listdir(disease_dir) if not f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"))])\n",
    "    print(f\"Loaded {len(images)} images from {split_dir} | Skipped {non_image_files} non-image files.\")\n",
    "    print(f\"Sample labels (first 5): {labels[:5]} - Types: {[type(l) for l in labels[:5]]}\")\n",
    "    return images, labels\n",
    "\n",
    "# --- Symptom Encoding ---\n",
    "def generate_symptom_array(label_index):\n",
    "    disease_name = list(disease_to_index.keys())[label_index]\n",
    "    symptoms = disease_symptoms[disease_name]\n",
    "    return sample(symptoms, randint(1, len(symptoms)))\n",
    "\n",
    "def encode_symptoms(symptom_list):\n",
    "    encoding = np.zeros(num_symptoms)\n",
    "    for sym in symptom_list:\n",
    "        encoding[symptom_to_index[sym]] = 1\n",
    "    return encoding\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, images, symptoms, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.symptoms = symptoms\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images[idx])\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, self.symptoms[idx], self.labels[idx]\n",
    "        return None, None, None\n",
    "\n",
    "# --- Data Preparation ---\n",
    "data = {}\n",
    "train_labels_flat = []\n",
    "\n",
    "# Load train and test images\n",
    "train_images, train_labels = load_images_from_split(TRAIN_DIR, \"train\")\n",
    "test_images, test_labels = load_images_from_split(TEST_DIR, \"test\")\n",
    "\n",
    "# Split train images into train and validation sets\n",
    "total_train_images = len(train_images)\n",
    "val_size = int(total_train_images * VALIDATION_SPLIT)\n",
    "train_size = total_train_images - val_size\n",
    "\n",
    "idx = list(range(total_train_images))\n",
    "random.shuffle(idx)\n",
    "train_idx = idx[:train_size]\n",
    "val_idx = idx[train_size:]\n",
    "\n",
    "# Ensure val_idx does not exceed original list length\n",
    "train_images_subset = [train_images[i] for i in train_idx]\n",
    "train_labels_subset = [train_labels[i] for i in train_idx]\n",
    "val_images_subset = [train_images[i] for i in val_idx if i < total_train_images]\n",
    "val_labels_subset = [train_labels[i] for i in val_idx if i < total_train_images]\n",
    "\n",
    "# Prepare symptoms and labels\n",
    "train_symptom_arrays = [generate_symptom_array(label) for label in train_labels_subset]\n",
    "train_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in train_symptom_arrays])\n",
    "val_symptom_arrays = [generate_symptom_array(label) for label in val_labels_subset]\n",
    "val_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in val_symptom_arrays])\n",
    "test_symptom_arrays = [generate_symptom_array(label) for label in test_labels]\n",
    "test_encoded_symptoms = np.array([encode_symptoms(symptoms) for symptoms in test_symptom_arrays])\n",
    "\n",
    "# Data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinDiseaseDataset(train_images_subset, train_encoded_symptoms, train_labels_subset, transform=data_transforms)\n",
    "val_dataset = SkinDiseaseDataset(val_images_subset, val_encoded_symptoms, val_labels_subset, transform=data_transforms)\n",
    "test_dataset = SkinDiseaseDataset(test_images, test_encoded_symptoms, test_labels, transform=data_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_labels_flat = np.array(train_labels_subset)\n",
    "\n",
    "# --- Debug Check ---\n",
    "print(f\"train_labels_flat content (first 5): {train_labels_flat[:5]}\")\n",
    "print(f\"train_labels_flat types (first 5): {[type(l) for l in train_labels_flat[:5]]}\")\n",
    "print(f\"Validation set size: {len(val_images_subset)}\")\n",
    "\n",
    "# --- Class Weights ---\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels_flat), y=train_labels_flat)\n",
    "class_weights = torch.FloatTensor(class_weights_array).to(device)\n",
    "\n",
    "# --- Model Builder ---\n",
    "class SkinDiseaseModel(nn.Module):\n",
    "    def __init__(self, base_model, num_symptoms, weights=None):\n",
    "        super(SkinDiseaseModel, self).__init__()\n",
    "        # Load the base model with weights parameter\n",
    "        self.base = base_model(weights=weights)\n",
    "        if isinstance(self.base, models.EfficientNet):\n",
    "            num_ftrs = self.base.classifier[1].in_features\n",
    "            self.base.classifier = nn.Identity()\n",
    "        elif isinstance(self.base, models.MobileNetV2):\n",
    "            num_ftrs = self.base.classifier[1].in_features\n",
    "            self.base.classifier = nn.Identity()\n",
    "        elif isinstance(self.base, models.VGG):\n",
    "            num_ftrs = self.base.classifier[6].in_features\n",
    "            self.base.classifier = nn.Identity()\n",
    "        else:\n",
    "            num_ftrs = self.base.fc.in_features\n",
    "            self.base.fc = nn.Identity()\n",
    "\n",
    "        # Fine-tune last few layers\n",
    "        params = list(self.base.parameters())\n",
    "        for param in params[:-2]:  # Freeze all but the last two parameter groups\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.image_fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512)\n",
    "        )\n",
    "        self.symptom_fc = nn.Sequential(\n",
    "            nn.Linear(num_symptoms, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.combined_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, symptoms):\n",
    "        x = self.base(image)\n",
    "        x = self.image_fc(x)\n",
    "        y = self.symptom_fc(symptoms)\n",
    "        combined = torch.cat((x, y), dim=1)\n",
    "        out = self.combined_fc(combined)\n",
    "        return out\n",
    "\n",
    "# --- Callbacks ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif val_loss > self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "class ReduceLROnPlateau:\n",
    "    def __init__(self, factor=0.5, patience=3, min_lr=1e-6):\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.lr = None\n",
    "\n",
    "    def __call__(self, val_loss, optimizer):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.counter = 0\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    self.lr = param_group['lr']\n",
    "                    new_lr = max(self.lr * self.factor, self.min_lr)\n",
    "                    param_group['lr'] = new_lr\n",
    "                    print(f'Reducing learning rate to {new_lr}')\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, model_name, early_stopping, reduce_lr):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, symptoms, labels in train_loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images, symptoms, labels = images.to(device), symptoms.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, symptoms.float())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "              f'Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        early_stopping(val_loss, model, os.path.join(OUTPUT_DIR, f'best_model_{model_name}.pth'))\n",
    "        reduce_lr(val_loss, optimizer)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate_model(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, symptoms, labels in loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images, symptoms, labels = images.to(device), symptoms.to(device), labels.to(device)\n",
    "            outputs = model(images, symptoms.float())\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = running_loss / len(loader.dataset) if criterion else 0.0\n",
    "    return loss, acc, all_preds, all_labels\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "def plot_training_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(disease_to_index.keys()), yticklabels=list(disease_to_index.keys()))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs, model_name):\n",
    "    y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(NUM_CLASSES):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {list(disease_to_index.keys())[i]} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Define models to train with appropriate weights\n",
    "    models_to_run = [\n",
    "        (\"EfficientNetB0\", models.efficientnet_b0, models.EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "        (\"MobileNetV2\", models.mobilenet_v2, models.MobileNet_V2_Weights.IMAGENET1K_V1),\n",
    "        (\"VGG16\", models.vgg16, models.VGG16_Weights.IMAGENET1K_V1),\n",
    "        (\"VGG19\", models.vgg19, models.VGG19_Weights.IMAGENET1K_V1)\n",
    "    ]\n",
    "\n",
    "    for model_name, base_model, weights in models_to_run:\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model = SkinDiseaseModel(base_model, num_symptoms, weights=weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        early_stopping = EarlyStopping(patience=5)\n",
    "        reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        model, history = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS, model_name, early_stopping, reduce_lr)\n",
    "\n",
    "        # Load best model and evaluate on all sets\n",
    "        model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, f'best_model_{model_name}.pth')))\n",
    "        model.eval()\n",
    "\n",
    "        # Train evaluation\n",
    "        train_loss, train_acc, _, _ = evaluate_model(model, train_loader, criterion)\n",
    "        print(f\"\\n{model_name} Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"{model_name} Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validation evaluation\n",
    "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion)\n",
    "        print(f\"{model_name} Val Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"{model_name} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Test evaluation\n",
    "        test_loss, test_acc, test_preds, test_labels = evaluate_model(model, test_loader, criterion)\n",
    "        print(f\"{model_name} Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"{model_name} Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Classification Report\n",
    "        report = classification_report(test_labels, test_preds, target_names=list(disease_to_index.keys()), output_dict=True)\n",
    "        print(f\"\\n{model_name} Classification Report:\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                print(f\"Class: {class_name}\")\n",
    "                print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "                print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "                print(f\"F1 Score: {metrics['f1-score']:.4f}\")\n",
    "                print(f\"Support: {metrics['support']:.0f}\")\n",
    "            elif class_name == 'accuracy':\n",
    "                print(f\"Accuracy: {metrics:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        plot_confusion_matrix(test_labels, test_preds, model_name)\n",
    "\n",
    "        # ROC and AUC\n",
    "        test_preds_probs = nn.functional.softmax(torch.tensor([model(images.to(device), symptoms.float()).cpu().detach().numpy() for images, symptoms, _ in test_loader]), dim=1).numpy()\n",
    "        plot_roc_curve(test_labels, test_preds_probs, model_name)\n",
    "\n",
    "        # Plot training history\n",
    "        plot_training_history(history, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
